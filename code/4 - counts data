# create counter object
from collections import Counter
results = Counter()

# create blank Dictionary to hold all words except excluded words from step 3
all_words = {}

# in dataframe column, split all words and update counts for each to counter object
df[job_des].str.split().apply(results.update)

print ("Frequency analysis for",len(df),role,"job listings")

# loops through counter object (top 1000 keyword value/count pairs)
for value, count in results.most_common(1000):
   if value.lower() not in excl_dict:
        # determines number of rows each value is contained in
        numRows = df[job_des].str.contains(value, na=False).value_counts()[True]

        # optional print list showing more data
        # print(value, count, numRows, "{:2.1%}".format(numRows/len(DF_8_SD.index)))

        # builds all_words dictionary with % occurence numbers
        all_words.update({value : numRows/len(df.index)})

# builds reverse (descending) order dictionary based on % occurence, and prints out to confirm
rev_all_words = sorted(all_words, key=all_words.get, reverse=True)
for r in rev_all_words:
    print(r,"{:2.1%}".format(all_words[r]))
